{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Подготовка"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## download data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "!wget -c https://www.dropbox.com/s/8lqrloi0mxj2acu/PH2Dataset.rar\n",
        "get_ipython().system_raw(\"unrar x PH2Dataset.rar\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Преобразуем данные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "from skimage.transform import resize\n",
        "size = (256, 256)\n",
        "X = [resize(x, size, mode='constant', anti_aliasing=True,) for x in images]\n",
        "Y = [resize(y, size, mode='constant', anti_aliasing=False) > 0.5 for y in lesions]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "X = np.array(X, np.float32)\n",
        "Y = np.array(Y, np.float32)\n",
        "print(f'Loaded {len(X)} images')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "ix = np.random.choice(len(X), len(X), False)\n",
        "tr, val, ts = np.split(ix, [100, 150])\n",
        "print(len(tr), len(val), len(ts))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Сделаем Dataloaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "batch_size = 25\n",
        "data_tr = DataLoader(list(zip(np.rollaxis(X[tr], 3, 1), Y[tr, np.newaxis])),\n",
        "                     batch_size=batch_size, shuffle=True)\n",
        "data_val = DataLoader(list(zip(np.rollaxis(X[val], 3, 1), Y[val, np.newaxis])),\n",
        "                      batch_size=batch_size, shuffle=True)\n",
        "data_ts = DataLoader(list(zip(np.rollaxis(X[ts], 3, 1), Y[ts, np.newaxis])),\n",
        "                     batch_size=batch_size, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "ds_dict = {'train': data_tr,\n",
        "           'valid': data_val,\n",
        "           'test_': data_ts}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import clear_output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "import torch.optim as optim\n",
        "from time import time\n",
        "\n",
        "from matplotlib import rcParams\n",
        "rcParams['figure.figsize'] = (15,4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MainCode"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SegNet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "class ConvNormBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, is_last_block=False):\n",
        "        super().__init__()\n",
        "        self.is_last_block = is_last_block\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "\n",
        "        if not self.is_last_block:\n",
        "            x = self.relu(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "class SegNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # encoder (downsampling)\n",
        "        # Each enc_conv/dec_conv block should look like this:\n",
        "        # nn.Sequential(\n",
        "        #     nn.Conv2d(...),\n",
        "        #     ... (2 or 3 conv layers with relu and batchnorm),\n",
        "        # )\n",
        "        #channels = 16\n",
        "        self.enc_conv0 = ConvNormBlock(3, 16)\n",
        "        self.pool0 = nn.MaxPool2d(2, 2, return_indices=True)  # 256 -> 128\n",
        "        self.enc_conv1 = ConvNormBlock(16, 32)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2, return_indices=True) # 128 -> 64\n",
        "        self.enc_conv2 = ConvNormBlock(32, 64)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2, return_indices=True) # 64 -> 32\n",
        "        self.enc_conv3 = ConvNormBlock(64, 128)\n",
        "        self.pool3 = nn.MaxPool2d(2, 2, return_indices=True) # 32 -> 16\n",
        "\n",
        "        # bottleneck\n",
        "        self.bottleneck_conv = ConvNormBlock(128, 128)\n",
        "\n",
        "        # decoder (upsampling)\n",
        "        self.upsample0 = nn.MaxUnpool2d(2, 2) # 16 -> 32\n",
        "        self.dec_conv0 = ConvNormBlock(128, 64)\n",
        "\n",
        "        self.upsample1 = nn.MaxUnpool2d(2, 2) # 32 -> 64\n",
        "        self.dec_conv1 = ConvNormBlock(64, 32)\n",
        "\n",
        "        self.upsample2 = nn.MaxUnpool2d(2, 2)  # 64 -> 128\n",
        "        self.dec_conv2 = ConvNormBlock(32, 16)\n",
        "\n",
        "        self.upsample3 = nn.MaxUnpool2d(2, 2)  # 128 -> 256\n",
        "        self.dec_conv3 = ConvNormBlock(16, 1, is_last_block=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # encoder\n",
        "        e, poll_ind0 = self.pool0(self.enc_conv0(x))\n",
        "        e, poll_ind1 = self.pool1(self.enc_conv1(e))\n",
        "        e, poll_ind2 = self.pool2(self.enc_conv2(e))\n",
        "        e, poll_ind3 = self.pool3(self.enc_conv3(e))\n",
        "\n",
        "        # bottleneck <1>\n",
        "        b = self.bottleneck_conv(e)\n",
        "\n",
        "        # decoder\n",
        "        d = self.dec_conv0(self.upsample0(b, indices=poll_ind3))\n",
        "        d = self.dec_conv1(self.upsample1(d, indices=poll_ind2))\n",
        "        d = self.dec_conv2(self.upsample2(d, indices=poll_ind1))\n",
        "        d = self.dec_conv3(self.upsample3(d, indices=poll_ind0))  # no activation\n",
        "        return torch.sigmoid(d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Functios"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "def iou_pytorch(outputs: torch.Tensor, labels: torch.Tensor):\n",
        "    # You can comment out this line if you are passing tensors of equal shape\n",
        "    # But if you are passing output from UNet or something it will most probably\n",
        "    # be with the BATCH x 1 x H x W shape\n",
        "\n",
        "    outputs = outputs.squeeze(1).byte()  # BATCH x 1 x H x W => BATCH x H x W\n",
        "    labels = labels.squeeze(1).byte()\n",
        "\n",
        "    SMOOTH = 1e-8\n",
        "    intersection = (outputs & labels).float().sum((1, 2))  # Will be zero if Truth=0 or Prediction=0\n",
        "    union = (outputs | labels).float().sum((1, 2))         # Will be zzero if both are 0\n",
        "\n",
        "    iou = (intersection + SMOOTH) / (union + SMOOTH)  # We smooth our devision to avoid 0/0\n",
        "\n",
        "    #print(iou)\n",
        "\n",
        "    thresholded = torch.clamp(20 * (iou - 0.5), 0, 10).ceil() / 10  # This is equal to comparing with thresolds\n",
        "\n",
        "    return thresholded  #"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "def train(model, opt, loss_fn, epochs, data_tr, data_val, show_plots=True):\n",
        "    losses = []\n",
        "    val_acc = []\n",
        "    X_val, Y_val = next(iter(data_val))\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        tic = time()\n",
        "        print('* Epoch %d/%d' % (epoch+1, epochs))\n",
        "\n",
        "        avg_loss = 0\n",
        "        model.train()  # train mode\n",
        "        for X_batch, Y_batch in data_tr:\n",
        "            # data to device\n",
        "            X_batch = X_batch.to(device)\n",
        "            Y_batch = Y_batch.to(device)\n",
        "            # set parameter gradients to zero\n",
        "            opt.zero_grad()\n",
        "            # forward\n",
        "\n",
        "            Y_pred = model(X_batch)\n",
        "            loss = loss_fn(Y_batch, Y_pred) # forward-pass\n",
        "            loss.backward()  # backward-pass\n",
        "            opt.step()  # update weights\n",
        "\n",
        "            # calculate loss to show the user\n",
        "            avg_loss += loss / len(data_tr)\n",
        "        toc = time()\n",
        "        print('loss: %f' % avg_loss)\n",
        "        losses.append(loss)\n",
        "\n",
        "        # show intermediate results\n",
        "        model.eval()  # testing mode\n",
        "        with torch.no_grad():\n",
        "            Y_hat = model(X_val.to(device)).cpu().detach()\n",
        "\n",
        "\n",
        "        # Visualize tools\n",
        "        if show_plots:\n",
        "            clear_output(wait=True)\n",
        "            for k in range(6):\n",
        "                plt.subplot(4, 6, k+1)\n",
        "                plt.imshow(np.rollaxis(X_val[k].numpy(), 0, 3), cmap='gray')\n",
        "                plt.title('Real')\n",
        "                plt.axis('off')\n",
        "\n",
        "                plt.subplot(4, 6, k+7)\n",
        "                plt.imshow(Y_hat[k, 0], cmap='gray')\n",
        "                plt.title('Pred')\n",
        "                plt.axis('off')\n",
        "\n",
        "                plt.subplot(4, 6, k+13)\n",
        "                plt.imshow(Y_val[k, 0], cmap='gray')\n",
        "                plt.title('True')\n",
        "                plt.axis('off')\n",
        "\n",
        "                plt.subplot(4, 6, k+19)\n",
        "                plt.imshow(Y_val[k, 0].byte() & Y_hat[k, 0].byte(), cmap='gray')\n",
        "                plt.title('Intersec')\n",
        "                plt.axis('off')\n",
        "            #plt.suptitle('%d / %d - loss: %f' % (epoch+1, epochs, avg_loss))\n",
        "            plt.show()\n",
        "\n",
        "        val_score = score_model(model, iou_pytorch, data_val, show_plots=False)\n",
        "        print('val score', val_score)\n",
        "        val_acc.append(val_score)\n",
        "        #print('val_acc', val_acc)\n",
        "    return losses, val_acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "def predict(model, data):\n",
        "    model.eval()  # testing mode\n",
        "    Y_pred = [ X_batch for X_batch, _ in data]\n",
        "    return np.array(Y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "def show_plot(data: torch.Tensor, title: str, xlabel: str, ylabel: str):\n",
        "    for i in range(len(data)):\n",
        "        data[i] = float(data[i])\n",
        "\n",
        "    plt.plot(data)\n",
        "    # Добавляем заголовок и метки осей\n",
        "    plt.title('title')\n",
        "    plt.xlabel('xlabel')\n",
        "    plt.ylabel('ylabel')\n",
        "\n",
        "    # Отображаем график\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "def model_full_score(model, ds_dict, treshold=0.5, show_plots=True, smooth_amout=0):\n",
        "    for ds_name, ds in ds_dict:\n",
        "        score = score_model(model,\n",
        "                            iou_pytorch,\n",
        "                            ds,\n",
        "                            show_plots=show_plots,\n",
        "                            smooth_amout=smooth_amout)\n",
        "        print(ds_name, f\"{score:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## BCELoss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "def bce_loss(y_real, y_pred):\n",
        "    # TODO\n",
        "    # please don't use nn.BCELoss. write it from scratch\n",
        "    loss = y_pred - y_real * y_pred + torch.log(1 + torch.exp(-y_pred))\n",
        "\n",
        "    # Усредняем потери по всем примерам\n",
        "    loss = torch.mean(loss)\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Dice Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "def dice_loss(y_real, y_pred):\n",
        "    smooth =  1e-8\n",
        "    num = 2 * (y_real * y_pred).sum()\n",
        "    den = y_real.sum() + y_pred.sum()\n",
        "    res = 1 - 1/(256*256) * ((num + smooth) / (den + smooth))\n",
        "    return res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Score model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "class Smoother(nn.Module):\n",
        "    def __init__(self, threshold=0.5):\n",
        "        super().__init__()\n",
        "        self.threshold = threshold\n",
        "\n",
        "    def forward(self, x):\n",
        "        binary_image = (x > self.threshold).float()\n",
        "\n",
        "        # Определение структурого элемента (3x3 окно)\n",
        "        kernel = torch.ones(1, 1, 3, 3).to(x.device)\n",
        "\n",
        "        # Применение операции свертки для подсчета суммы значений в 3x3 окрестности\n",
        "        neighbor_sum = F.conv2d(binary_image, kernel, padding=1)\n",
        "\n",
        "        # Создание маски: пиксели, у которых сумма в окрестности >= 3, становятся белыми\n",
        "        mask = (neighbor_sum >= 7).float()\n",
        "\n",
        "        # Применение маски к бинарному изображению\n",
        "        filtered_image = binary_image * mask\n",
        "\n",
        "        return filtered_image\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "def score_model(model, metric, data, treshold=0.5, show_plots=True, smooth_amout=0):\n",
        "    #3#\n",
        "    smooth_it = Smoother()\n",
        "\n",
        "    X_val, Y_val = next(iter(data))\n",
        "    model.eval()  # testing mode\n",
        "    with torch.no_grad():\n",
        "        Y_hat = model(X_val.to(device)).cpu().detach()\n",
        "\n",
        "    Y_hat = Y_hat > 0.5\n",
        "    for i in range(smooth_amout):\n",
        "        Y_hat = smooth_it(Y_hat)\n",
        "\n",
        "\n",
        "    if show_plots:\n",
        "    # Visualize tools\n",
        "        clear_output(wait=True)\n",
        "        for k in range(6):\n",
        "            plt.subplot(4, 6, k+1)\n",
        "            plt.imshow(np.rollaxis(X_val[k].numpy(), 0, 3), cmap='gray')\n",
        "            plt.title('Real')\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.subplot(4, 6, k+7)\n",
        "            plt.imshow(Y_hat[k, 0], cmap='gray')\n",
        "            plt.title('Pred')\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.subplot(4, 6, k+13)\n",
        "            plt.imshow(Y_val[k, 0], cmap='gray')\n",
        "            plt.title('True')\n",
        "            plt.axis('off')\n",
        "\n",
        "            plt.subplot(4, 6, k+19)\n",
        "            plt.imshow(Y_val[k, 0].byte() & Y_hat[k, 0].byte(), cmap='gray')\n",
        "            plt.title('Intersec')\n",
        "            plt.axis('off')\n",
        "        #plt.suptitle('%d / %d - loss: %f' % (epoch+1, epochs, avg_loss))\n",
        "        plt.show()\n",
        "    #3#\n",
        "    model.eval()  # переводим модель в режим тестирования\n",
        "    scores = 0\n",
        "    with torch.no_grad():\n",
        "        for X_batch, Y_label in data:\n",
        "            # Отправляем данные на устройство (GPU, если доступно)\n",
        "            X_batch = X_batch.to(device)\n",
        "            Y_label = Y_label.to(device)\n",
        "            # Прямой проход (forward pass) для получения предсказаний\n",
        "            Y_pred = model(X_batch) > treshold # treshold to binarize matrix\n",
        "            for i in range(smooth_amout):\n",
        "                Y_pred = smooth_it(Y_pred)\n",
        "            # Вычисляем метрику на текущем батче и суммируем\n",
        "\n",
        "            scores += metric(Y_label, Y_pred).mean().item()\n",
        "\n",
        "    # Возвращаем усредненную метрику по всем батчам\n",
        "    return scores / len(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Обучение"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SegNet + bceloss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "model = SegNet().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "max_epochs = 20\n",
        "optim = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
        "train(model, optim, bce_loss, max_epochs, data_tr, data_val)\n",
        "None"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "model_full_score(model, ds_dict, show_plots=False, smooth_amout=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SegNet + diceloss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "model_dice = SegNet().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "max_epochs = 40\n",
        "optimaizer = torch.optim.Adam(model_dice.parameters())\n",
        "train(model_dice, optimaizer, dice_loss, max_epochs, data_tr, data_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "model_full_score(model_dice, ds_dict, show_plots=False, smooth_amout=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## SimpleSegNet"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SimpleSegNet code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "class SimpleConvNormBlock(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, is_last_block=False):\n",
        "        super().__init__()\n",
        "        self.is_last_block = is_last_block\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "\n",
        "        if not self.is_last_block:\n",
        "            x = self.relu(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "class SimpleSegNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # encoder (downsampling)\n",
        "        # Each enc_conv/dec_conv block should look like this:\n",
        "        # nn.Sequential(\n",
        "        #     nn.Conv2d(...),\n",
        "        #     ... (2 or 3 conv layers with relu and batchnorm),\n",
        "        # )\n",
        "        #channels = 16\n",
        "        self.enc_conv0 = SimpleConvNormBlock(3, 16)\n",
        "        self.pool0 = nn.MaxPool2d(2, 2, return_indices=True)  # 256 -> 128\n",
        "        self.enc_conv1 = SimpleConvNormBlock(16, 32)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2, return_indices=True) # 128 -> 64\n",
        "        self.enc_conv2 = SimpleConvNormBlock(32, 64)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2, return_indices=True) # 64 -> 32\n",
        "        self.enc_conv3 = SimpleConvNormBlock(64, 128)\n",
        "        self.pool3 = nn.MaxPool2d(2, 2, return_indices=True) # 32 -> 16\n",
        "\n",
        "        # bottleneck\n",
        "        self.bottleneck_conv = SimpleConvNormBlock(128, 128)\n",
        "\n",
        "        # decoder (upsampling)\n",
        "        self.upsample0 = nn.MaxUnpool2d(2, 2) # 16 -> 32\n",
        "        self.dec_conv0 = SimpleConvNormBlock(128, 64)\n",
        "\n",
        "        self.upsample1 = nn.MaxUnpool2d(2, 2) # 32 -> 64\n",
        "        self.dec_conv1 = SimpleConvNormBlock(64, 32)\n",
        "\n",
        "        self.upsample2 = nn.MaxUnpool2d(2, 2)  # 64 -> 128\n",
        "        self.dec_conv2 = SimpleConvNormBlock(32, 16)\n",
        "\n",
        "        self.upsample3 = nn.MaxUnpool2d(2, 2)  # 128 -> 256\n",
        "        self.dec_conv3 = SimpleConvNormBlock(16, 1, is_last_block=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # encoder\n",
        "        e, poll_ind0 = self.pool0(self.enc_conv0(x))\n",
        "        e, poll_ind1 = self.pool1(self.enc_conv1(e))\n",
        "        e, poll_ind2 = self.pool2(self.enc_conv2(e))\n",
        "        e, poll_ind3 = self.pool3(self.enc_conv3(e))\n",
        "\n",
        "        # bottleneck <1>\n",
        "        b = self.bottleneck_conv(e)\n",
        "\n",
        "        # decoder\n",
        "        d = self.dec_conv0(self.upsample0(b, indices=poll_ind3))\n",
        "        d = self.dec_conv1(self.upsample1(d, indices=poll_ind2))\n",
        "        d = self.dec_conv2(self.upsample2(d, indices=poll_ind1))\n",
        "        d = self.dec_conv3(self.upsample3(d, indices=poll_ind0))  # no activation\n",
        "        return torch.sigmoid(d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SimpSegNet train and evaluating"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### SimpleSegNet + bceloss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "simple_seg_model = SimpleSegNet().to(device)\n",
        "max_epochs = 20\n",
        "optim = torch.optim.Adam(simple_seg_model.parameters(), lr=3e-4)\n",
        "train(simple_seg_model, optim, bce_loss, max_epochs, data_tr, data_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "model_full_score(simple_seg_model, ds_dict, show_plots=False, smooth_amout=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### SimpleSegNet + diceloss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "simple_dice_seg_model = SimpleSegNet().to(device)\n",
        "max_epochs = 40\n",
        "optimaizer = torch.optim.Adam(simple_dice_seg_model.parameters())\n",
        "train(simple_dice_seg_model, optimaizer, dice_loss, max_epochs, data_tr, data_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "model_full_score(simple_dice_seg_model, ds_dict, show_plots=False, smooth_amout=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Вывод"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Focal Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "def focal_loss(y_real, y_pred, eps = 1e-8, gamma = 2):\n",
        "\n",
        "    summand1 = torch.pow((1 - y_pred), gamma) * y_real * torch.log(y_pred + eps)\n",
        "    summand2 = (1 - y_pred) * torch.log(1 - y_pred + eps)\n",
        "\n",
        "    loss = -torch.sum(summand1 + summand2) / y_pred.size(0)\n",
        "    #y_pred =  # hint: torch.clamp # чет я не понял зачем это, но когда словлю ошибку пойму\n",
        "    #print(summand1)\n",
        "    #print(summand2)\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "class FocalLoss:\n",
        "    def __init__(self, gamma = 2):\n",
        "        self.gamma = gamma\n",
        "    def __call__(self, y_real, y_pred):\n",
        "\n",
        "        return focal_loss(y_real, y_pred, gamma=self.gamma)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SegNet + FocalLoss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### SegNet + FocalLoss + gamma=2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "model_focal = SegNet().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "max_epochs = 150\n",
        "optimaizer = optim.Adam(model_focal.parameters(), lr=3e-4)\n",
        "losses, val_acc = train(model_focal, optimaizer, focal_loss, max_epochs, data_tr, data_val, show_plots=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "model_full_score(model_focal, ds_dict, show_plots=False, smooth_amout=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### SegNet + FocalLoss + gamma=4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "model_focal_4 = SegNet().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "foc_los = FocalLoss(gamma=4)\n",
        "max_epochs = 150\n",
        "optimaizer = optim.Adam(model_focal_4.parameters(), lr=3e-4)\n",
        "losses, val_acc = train(model_focal_4, optimaizer, foc_los, max_epochs, data_tr, data_val, show_plots=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "model_full_score(model_focal_4, ds_dict, show_plots=False, smooth_amout=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### SegNet + FocalLoss + gamma=6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "model_focal_6 = SegNet().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "foc_los = FocalLoss(gamma=6)\n",
        "max_epochs = 150\n",
        "optimaizer = optim.Adam(model_focal_6.parameters(), lr=3e-4)\n",
        "losses, val_acc = train(model_focal_6, optimaizer, foc_los, max_epochs, data_tr, data_val, show_plots=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "model_full_score(model_focal_6, ds_dict, show_plots=False, smooth_amout=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### SegNet + FocalLoss + gamma=1.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "model_focal_15 = SegNet().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "foc_los = FocalLoss(gamma=1.3)\n",
        "max_epochs = 150\n",
        "optimaizer = optim.Adam(model_focal_15.parameters(), lr=3e-4)\n",
        "losses, val_acc = train(model_focal_15, optimaizer, foc_los, max_epochs, data_tr, data_val, show_plots=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "model_full_score(model_focal_15, ds_dict, show_plots=False, smooth_amout=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Total Variation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "def total_variation(image):\n",
        "    \"\"\"\n",
        "    Вычисляет Total Variation (TV) на изображении.\n",
        "\n",
        "    Args:\n",
        "        image (torch.Tensor): Изображение, представленное в виде тензора (batch_size, channels, height, width).\n",
        "\n",
        "    Returns:\n",
        "        torch.Tensor: Значение Total Variation.\n",
        "    \"\"\"\n",
        "    # Вычисляем разницу между соседними пикселями по горизонтали и вертикали\n",
        "    horizontal_diff = image[:, :, :, :-1] - image[:, :, :, 1:]\n",
        "    vertical_diff = image[:, :, :-1, :] - image[:, :, 1:, :]\n",
        "\n",
        "    # Суммируем абсолютные значения разницы\n",
        "    tv = torch.sum(torch.abs(horizontal_diff)) + torch.sum(torch.abs(vertical_diff))\n",
        "\n",
        "    return tv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "wrapper to use loss func and tv together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "class LossPlusTV:\n",
        "    def __init__(self, loss_func, alpha_loss, alpha_tv):\n",
        "        self.loss = loss_func\n",
        "        self.alpha_loss = alpha_loss\n",
        "        self.alpha_tv = alpha_tv\n",
        "\n",
        "    def __call__(self, y_real, y_pred):\n",
        "        loss = self.loss(y_real=y_real, y_pred=y_pred)\n",
        "        tv = total_variation(y_pred)\n",
        "        #print('loss', self.alpha_loss * loss)\n",
        "        #print('tv', self.alpha_tv*tv)\n",
        "        return self.alpha_loss * loss + self.alpha_tv * tv\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### SegNet + Dice + TV"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### SegNet + Dice + TV + alpha_loss=5, alpha_tv=0.000_000_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "model_dice_tv = SegNet().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "dice_tv_los = LossPlusTV(bce_loss, alpha_loss=5, alpha_tv=0.000_000_1)\n",
        "max_epochs = 150\n",
        "optimaizer = torch.optim.Adam(model_dice_tv.parameters(), lr=3e-4)\n",
        "losses, val_acc = train(model_dice_tv, optimaizer, dice_tv_los, max_epochs, data_tr, data_val, show_plots=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "model_full_score(model_dice_tv, ds_dict, show_plots=False, smooth_amout=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### SegNet + Dice + TV + alpha_loss=1, alpha_tv=0.000_000_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "model_dice_tv = SegNet().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "dice_tv_los = LossPlusTV(bce_loss, alpha_loss=1, alpha_tv=0.000_000_1)\n",
        "max_epochs = 150\n",
        "optimaizer = torch.optim.Adam(model_dice_tv.parameters(), lr=3e-4)\n",
        "losses, val_acc = train(model_dice_tv, optimaizer, dice_tv_los, max_epochs, data_tr, data_val, show_plots=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "model_full_score(model_dice_tv, ds_dict, show_plots=False, smooth_amout=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## U-Net"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### U-net skipconnection = sum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # encoder (downsampling)\n",
        "        # Each enc_conv/dec_conv block should look like this:\n",
        "        # nn.Sequential(\n",
        "        #     nn.Conv2d(...),\n",
        "        #     ... (2 or 3 conv layers with relu and batchnorm),\n",
        "        # )\n",
        "        self.enc_conv0 = ConvNormBlock(3, 16)\n",
        "        self.pool0 = nn.MaxPool2d(2, 2, return_indices=True)  # 256 -> 128\n",
        "        self.enc_conv1 = ConvNormBlock(16, 32)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2, return_indices=True) # 128 -> 64\n",
        "        self.enc_conv2 = ConvNormBlock(32, 64)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2, return_indices=True) # 64 -> 32\n",
        "        self.enc_conv3 = ConvNormBlock(64, 128)\n",
        "        self.pool3 = nn.MaxPool2d(2, 2, return_indices=True) # 32 -> 16\n",
        "\n",
        "        # bottleneck\n",
        "        self.bottleneck_conv = ConvNormBlock(128, 128)\n",
        "\n",
        "        # decoder (upsampling)\n",
        "        self.upsample0 = nn.MaxUnpool2d(2, 2) # 16 -> 32\n",
        "        self.dec_conv0 = ConvNormBlock(128, 64)\n",
        "\n",
        "        self.upsample1 = nn.MaxUnpool2d(2, 2) # 32 -> 64\n",
        "        self.dec_conv1 = ConvNormBlock(64, 32)\n",
        "\n",
        "        self.upsample2 = nn.MaxUnpool2d(2, 2)  # 64 -> 128\n",
        "        self.dec_conv2 = ConvNormBlock(32, 16)\n",
        "\n",
        "        self.upsample3 = nn.MaxUnpool2d(2, 2)  # 128 -> 256\n",
        "        self.dec_conv3 = ConvNormBlock(16, 1, is_last_block=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # encoder\n",
        "        e0 = self.enc_conv0(x)\n",
        "        e, poll_ind0 = self.pool0(e0)\n",
        "\n",
        "        e1 = self.enc_conv1(e)\n",
        "        e, poll_ind1 = self.pool1(e1)\n",
        "\n",
        "        e2 = self.enc_conv2(e)\n",
        "        e, poll_ind2 = self.pool2(e2)\n",
        "\n",
        "        e3 = self.enc_conv3(e)\n",
        "        e, poll_ind3 = self.pool3(e3)\n",
        "\n",
        "        # bottleneck <1>\n",
        "        b = self.bottleneck_conv(e)\n",
        "\n",
        "        # decoder\n",
        "        d = self.dec_conv0(self.upsample0(b, indices=poll_ind3) + e3)\n",
        "        d = self.dec_conv1(self.upsample1(d, indices=poll_ind2) + e2)\n",
        "        d = self.dec_conv2(self.upsample2(d, indices=poll_ind1) + e1)\n",
        "        d = self.dec_conv3(self.upsample3(d, indices=poll_ind0) + e0)  # no activation\n",
        "        return torch.sigmoid(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "unet_sum_model = UNet().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "ma_opt = torch.optim.Adam(unet_sum_model.parameters(), lr=3e-4)\n",
        "max_epochs = 150\n",
        "losses, val_acc = train(unet_sum_model, ma_opt, bce_loss, max_epochs, data_tr, data_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "model_full_score(unet_sum_model, ds_dict, show_plots=False, smooth_amout=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### U-net skipconnection = concatenation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "class UNetCon(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # encoder (downsampling)\n",
        "        # Each enc_conv/dec_conv block should look like this:\n",
        "        # nn.Sequential(\n",
        "        #     nn.Conv2d(...),\n",
        "        #     ... (2 or 3 conv layers with relu and batchnorm),\n",
        "        # )\n",
        "        self.enc_conv0 = ConvNormBlock(3, 16)\n",
        "        self.pool0 = nn.MaxPool2d(2, 2, return_indices=True)  # 256 -> 128\n",
        "        self.enc_conv1 = ConvNormBlock(16, 32)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2, return_indices=True) # 128 -> 64\n",
        "        self.enc_conv2 = ConvNormBlock(32, 64)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2, return_indices=True) # 64 -> 32\n",
        "        self.enc_conv3 = ConvNormBlock(64, 128)\n",
        "        self.pool3 = nn.MaxPool2d(2, 2, return_indices=True) # 32 -> 16\n",
        "\n",
        "        # bottleneck\n",
        "        self.bottleneck_conv = ConvNormBlock(128, 128)\n",
        "\n",
        "        # decoder (upsampling)\n",
        "        self.upsample0 = nn.MaxUnpool2d(2, 2) # 16 -> 32\n",
        "        self.dec_conv0 = ConvNormBlock(128*2, 64)\n",
        "\n",
        "        self.upsample1 = nn.MaxUnpool2d(2, 2) # 32 -> 64\n",
        "        self.dec_conv1 = ConvNormBlock(64*2, 32)\n",
        "\n",
        "        self.upsample2 = nn.MaxUnpool2d(2, 2)  # 64 -> 128\n",
        "        self.dec_conv2 = ConvNormBlock(32*2, 16)\n",
        "\n",
        "        self.upsample3 = nn.MaxUnpool2d(2, 2)  # 128 -> 256\n",
        "        self.dec_conv3 = ConvNormBlock(16*2, 1, is_last_block=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # encoder\n",
        "        e0 = self.enc_conv0(x)\n",
        "        e, poll_ind0 = self.pool0(e0)\n",
        "\n",
        "        e1 = self.enc_conv1(e)\n",
        "        e, poll_ind1 = self.pool1(e1)\n",
        "\n",
        "        e2 = self.enc_conv2(e)\n",
        "        e, poll_ind2 = self.pool2(e2)\n",
        "\n",
        "        e3 = self.enc_conv3(e)\n",
        "        e, poll_ind3 = self.pool3(e3)\n",
        "\n",
        "        # bottleneck <1>\n",
        "        b = self.bottleneck_conv(e)\n",
        "\n",
        "        # decoder\n",
        "        d= torch.cat((self.upsample0(b, indices=poll_ind3), e3), dim=1)\n",
        "        d = self.dec_conv0(d)\n",
        "\n",
        "        d = torch.cat((self.upsample1(d, indices=poll_ind2), e2), dim=1)\n",
        "        d = self.dec_conv1(d)\n",
        "\n",
        "        d = torch.cat((self.upsample2(d, indices=poll_ind1), e1), dim=1)\n",
        "        d = self.dec_conv2(d)\n",
        "\n",
        "        d = torch.cat((self.upsample3(d, indices=poll_ind0), e0), dim=1)\n",
        "        d = self.dec_conv3(d)  # no activation\n",
        "        return torch.sigmoid(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "unet_con_model = UNetCon().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "\n",
        "ma_opt = torch.optim.Adam(unet_con_model.parameters(), lr=3e-4)\n",
        "max_epochs = 150\n",
        "losses, val_acc = train(unet_con_model, ma_opt, bce_loss, max_epochs, data_tr, data_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "model_full_score(unet_con_model, ds_dict, show_plots=False, smooth_amout=0)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### U-net 2 (concat + conv_stride=2 + trans_conv_stride=2) \n",
        " skipconnection = concatenation + max-pooling = convolutions с stride=2 + upsampling = transpose-convolutions с stride=2."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "class UNet2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        # encoder (downsampling)\n",
        "        # Each enc_conv/dec_conv block should look like this:\n",
        "        # nn.Sequential(\n",
        "        #     nn.Conv2d(...),\n",
        "        #     ... (2 or 3 conv layers with relu and batchnorm),\n",
        "        # )\n",
        "        self.enc_conv0 = ConvNormBlock(3, 16)\n",
        "        self.pool0 = nn.Conv2d(16, 16, kernel_size=3, padding=1, stride=2)  # 256 -> 128\n",
        "\n",
        "        self.enc_conv1 = ConvNormBlock(16, 32)\n",
        "        self.pool1 = nn.Conv2d(32, 32, kernel_size=3, padding=1, stride=2) # 128 -> 64\n",
        "\n",
        "        self.enc_conv2 = ConvNormBlock(32, 64)\n",
        "        self.pool2 = nn.Conv2d(64, 64, kernel_size=3, padding=1, stride=2) # 64 -> 32\n",
        "\n",
        "        self.enc_conv3 = ConvNormBlock(64, 128)\n",
        "        self.pool3 = nn.Conv2d(128, 128, kernel_size=3, padding=1, stride=2) # 32 -> 16\n",
        "\n",
        "        # bottleneck\n",
        "        self.bottleneck_conv = ConvNormBlock(128, 128)\n",
        "\n",
        "        # decoder (upsampling)\n",
        "        self.upsample0 = nn.ConvTranspose2d(in_channels=128, out_channels=128, kernel_size=2, stride=2, padding=0)\n",
        "        self.dec_conv0 = ConvNormBlock(128*2, 64)\n",
        "\n",
        "        self.upsample1 = nn.ConvTranspose2d(in_channels=64, out_channels=64, kernel_size=2, stride=2, padding=0) # 32 -> 64\n",
        "        self.dec_conv1 = ConvNormBlock(64*2, 32)\n",
        "\n",
        "        self.upsample2 = nn.ConvTranspose2d(in_channels=32, out_channels=32, kernel_size=2, stride=2, padding=0)  # 64 -> 128\n",
        "        self.dec_conv2 = ConvNormBlock(32*2, 16)\n",
        "\n",
        "        self.upsample3 = nn.ConvTranspose2d(in_channels=16, out_channels=16, kernel_size=2, stride=2, padding=0)  # 128 -> 256\n",
        "        self.dec_conv3 = ConvNormBlock(16*2, 1, is_last_block=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # encoder\n",
        "        e0 = self.enc_conv0(x)\n",
        "        e = self.pool0(e0)\n",
        "\n",
        "        e1 = self.enc_conv1(e)\n",
        "        e = self.pool1(e1)\n",
        "\n",
        "        e2 = self.enc_conv2(e)\n",
        "        e = self.pool2(e2)\n",
        "\n",
        "        e3 = self.enc_conv3(e)\n",
        "        e= self.pool3(e3)\n",
        "\n",
        "        # bottleneck <1>\n",
        "        b = self.bottleneck_conv(e)\n",
        "\n",
        "        # decoder\n",
        "\n",
        "        d= torch.cat((self.upsample0(b), e3), dim=1)\n",
        "        d = self.dec_conv0(d)\n",
        "        #print('e3',e2.shape, 'ups', self.upsample1(d).shape)\n",
        "        d = torch.cat((self.upsample1(d), e2), dim=1)\n",
        "        d = self.dec_conv1(d)\n",
        "\n",
        "        d = torch.cat((self.upsample2(d), e1), dim=1)\n",
        "        d = self.dec_conv2(d)\n",
        "\n",
        "        d = torch.cat((self.upsample3(d), e0), dim=1)\n",
        "        d = self.dec_conv3(d)  # no activation\n",
        "        return torch.sigmoid(d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "unet2_model = UNet2().to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "ma_opt = torch.optim.Adam(unet2_model.parameters(), lr=3e-4)\n",
        "max_epochs = 150\n",
        "losses, val_acc = train(unet2_model, ma_opt, bce_loss, max_epochs, data_tr, data_val)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        }
      },
      "outputs": [],
      "source": [
        "model_full_score(unet2_model, ds_dict, show_plots=False, smooth_amout=0)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
